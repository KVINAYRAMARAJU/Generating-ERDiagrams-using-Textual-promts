{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb3d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vinay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "import matplotlib.pyplot as mtp  \n",
    "from sklearn import svm,naive_bayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as mtp  \n",
    "from sklearn import svm,naive_bayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304a894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: language-tool-python in c:\\users\\vinay\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from language-tool-python) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from language-tool-python) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tqdm->language-tool-python) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install language-tool-python  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4ca58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing for testing to remove spelling mistakes\n",
    "\n",
    "# importing the library  \n",
    "import language_tool_python  \n",
    "  \n",
    "# creating the tool  \n",
    "spell_correction = language_tool_python.LanguageTool('en-US')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6023356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\vinay\\anaconda3\\lib\\site-packages (0.20.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f0a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b84cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\vinay\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vinay\\anaconda3\\lib\\site-packages (9.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14156d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[67]:\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"modifications_dataset.csv\")\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "df.tail()\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "df.isnull().any()\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "numerical_data=df.select_dtypes(include=[np.number])\n",
    "categorical_data=df.select_dtypes(exclude=[np.number])\n",
    "\n",
    "\n",
    "# In[74]:\n",
    "\n",
    "\n",
    "for x in categorical_data:\n",
    "    df[x] = df[x].fillna(df[x].mode()[0])\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "for x in numerical_data:\n",
    "    df[x] = df[x].fillna(df[x].median())\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc_data = enc.fit_transform(categorical_data)\n",
    "\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "data_enc  = pd.DataFrame(enc_data, columns=categorical_data.columns)\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "data_out = pd.concat([data_enc,numerical_data], axis=1) \n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "X = df[['Word', 'POS']].apply(lambda x: ' '.join(x), axis=1)\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "# Convert the words to a matrix of token counts\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "# Convert the test words to a matrix of token counts\n",
    "X_test_counts = vectorizer.transform(X_test.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "# Use the classifier to predict the labels of the test set\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "592ba4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a university a student enrolls in courses. a student must assigned to at least one or more courses. a courses can assigned to more than one students. each course is taught by a single professor. to maintain instruction quality a professor can deliver only one course\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "#text= \"In a university, a Student enrolls in Courses. A student must be assigned to at least one or variou other Course. A courses can be assigned to more than one students. Each course is taught by a single Professor. To maintain instruction quality, a Professor can deliver only one course\"\n",
    "#text = \"Employee Provides their attendence Daily. He will be able to apply more than one leave. He can apply for Expenses. He gives their rating. Manager may approve Leave of their employees. She can approve expences applied by Employees.\" \n",
    "#text = \"A salesperson may manage many other salespeople. A salesperson is managed by only one salespeople. A salesperson can be an agent for many customers. A customer is managed by one salespeople. A customer can place many orders. An order can be placed by one customer. An order can lists many inventory items. An inventory item may be listed on many orders. An inventory item is assembled from many parts. A part may be assembled into many inventory items. Many employees assemble an inventory item from many parts. A supplier can supply many parts. A part may be supplied by many suppliers\"\n",
    "#text = input(\"Enter Text\")\n",
    "#text without inventory\n",
    "#main \n",
    "#text = \"A salesperson may manage many other salespeople. A salesperson is managed by only one salespeople. A salesperson can be an agent for many customers. A customer is managed by one salespeople. A customer can place many orders. An order can be placed by one customer. An order may lists many items. An item may be listed on many orders. An item is assembled from many parts. A part may be assembled into many items. Many employees assemble an item from many parts. A supplier can supply many parts. A part may be supplied by many suppliers\"\n",
    "#text1\n",
    "#text = \"HR will add positions. Recruiter will check positions. Recruiter will add candidates. HR will schedule interview. Candidate will attend interview. Interviewer will be interviewing the candidate. HR will select a candidate. \"\n",
    "#text2\n",
    "#text = \"Employee Provides their attendence Daily. Employees will be able to apply more than one leave. Employees can apply for Expenses. Manager may approve Leave of their employees. manager can approve expenses applied by Employees.\" \n",
    "#text3\n",
    "text = \"In a university, a Student enrolls in Courses. A student must be assigned to at least one or more Courses. A courses can be assigned to more than one students. Each course is taught by a single Professor. To maintain instruction quality, a Professor can deliver only one course\"\n",
    "#text4 \n",
    "#text = \"HR will add positions. Recruiter will be checking some postions. Recruiter will add add candidates. HR will schedule interview. Candidate will attend interview. HR may select that candidate. \"\n",
    "\n",
    "# remove Spell and grammer correction  \n",
    "# text = spell_correction.correct(text)  \n",
    "\n",
    "#In[65]:\n",
    "\n",
    "text = text.lower()\n",
    "bad_chars = [';', ':', '!', \"*\",\"@\",\"(\",\")\",\",\",\"be \",\" be\"]\n",
    "# using replace() to\n",
    "# remove bad_chars\n",
    "for i in bad_chars:\n",
    "\ttext = text.replace(i, '')\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a402e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('in', 'IN'), ('a', 'DT'), ('university', 'NN'), ('a', 'DT'), ('student', 'NN'), ('enrolls', 'VBZ'), ('in', 'IN'), ('course', 'NNS'), ('.', '.')], [('a', 'DT'), ('student', 'NN'), ('must', 'MD'), ('assign', 'VBN'), ('to', 'TO'), ('at', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('course', 'NNS'), ('.', '.')], [('a', 'DT'), ('course', 'NNS'), ('can', 'MD'), ('assign', 'VB'), ('to', 'TO'), ('more', 'JJR'), ('than', 'IN'), ('one', 'CD'), ('student', 'NNS'), ('.', '.')], [('each', 'DT'), ('course', 'NN'), ('is', 'VBZ'), ('teach', 'VBN'), ('by', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('professor', 'NN'), ('.', '.')], [('to', 'TO'), ('maintain', 'VB'), ('instruction', 'NN'), ('quality', 'NN'), ('a', 'DT'), ('professor', 'NN'), ('can', 'MD'), ('deliver', 'VB'), ('only', 'RB'), ('one', 'CD'), ('course', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "array_m = []\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    # POS tagging using the Averaged Perceptron Tagger\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize each word based on its POS tag\n",
    "    lemmas = []\n",
    "    for word, tag in pos_tags:\n",
    "        if tag in ['NNS', 'NNPS', 'POS']:\n",
    "            lemma = lemmatizer.lemmatize(word, pos='n')\n",
    "        elif tag in ['RB', 'VBD', 'VBN', 'VBG', 'VB']:\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        else:\n",
    "            lemma = word\n",
    "        lemmas.append((lemma, tag))\n",
    "    \n",
    "    array_m.append(lemmas)\n",
    "\n",
    "print(array_m)\n",
    "df_m = pd.DataFrame(array_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "358dbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('university', 'NN', 'Entity'), ('student', 'NN', 'Entity'), ('enrolls', 'VBZ', 'Relation'), ('course', 'NNS', 'Entity'), ('student', 'NN', 'Entity'), ('assign', 'VBN', 'Relation'), ('one', 'CD', 'Number'), ('course', 'NNS', 'Entity'), ('course', 'NNS', 'Entity'), ('assign', 'VB', 'Relation'), ('one', 'CD', 'Number'), ('student', 'NNS', 'Entity'), ('course', 'NN', 'Entity'), ('teach', 'VBN', 'Relation'), ('single', 'JJ', 'Attribute'), ('professor', 'NN', 'Entity'), ('maintain', 'VB', 'Relation'), ('instruction', 'NN', 'Entity'), ('quality', 'NN', 'Entity'), ('professor', 'NN', 'Entity'), ('deliver', 'VB', 'Relation'), ('one', 'CD', 'Number'), ('course', 'NN', 'Entity')]\n"
     ]
    }
   ],
   "source": [
    "# In[85]:\n",
    "\n",
    "\n",
    "array = []\n",
    "for i in range(df_m.shape[0]):\n",
    "    for j in range(df_m.shape[1]):\n",
    "        word_pos = df_m.iloc[i, j] # Updated indexing with iloc\n",
    "        if word_pos is not None:\n",
    "            word_counts = vectorizer.transform([' '.join(word_pos)])\n",
    "            label = clf.predict(word_counts)[0]\n",
    "            if label != \"O\":\n",
    "                temp = df_m.iloc[i, j] + (label,) # Updated indexing with iloc\n",
    "                array.append(temp)\n",
    "array_list = [tuple(item) for item in array]\n",
    "print(array_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "47acbf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('university', 'NN', 'Entity'), ('student', 'NN', 'Entity'), ('enrolls', 'VBZ', 'Relation'), ('course', 'NNS', 'Entity'), ('student', 'NN', 'Entity'), ('assign', 'VBN', 'Relation'), ('one', 'CD', 'Number'), ('course', 'NNS', 'Entity'), ('course', 'NNS', 'Entity'), ('assign', 'VB', 'Relation'), ('one', 'CD', 'Number'), ('student', 'NNS', 'Entity'), ('course', 'NN', 'Entity'), ('teach', 'VBN', 'Relation'), ('single', 'JJ', 'Attribute'), ('professor', 'NN', 'Entity'), ('maintain', 'VB', 'Relation'), ('instruction', 'NN', 'Entity'), ('quality', 'NN', 'Entity'), ('professor', 'NN', 'Entity'), ('deliver', 'VB', 'Relation'), ('one', 'CD', 'Number'), ('course', 'NN', 'Entity')]\n"
     ]
    }
   ],
   "source": [
    "# code if text has many,more,various make next NN as NNS\n",
    "\n",
    "output = array_list\n",
    "flag = False\n",
    "for i, (word, tag, label) in enumerate(output):\n",
    "    if word in ['many','more','various','numerous','abundant','multiple','several','plenty']:\n",
    "        flag = True\n",
    "        output[i] = (word, 'JJ', 'O')\n",
    "    if flag and label == 'Entity':\n",
    "        output[i] = (word, 'NNS', 'Entity')\n",
    "        flag = False\n",
    "#     if word == 'many' or word == 'more' or word == 'various':\n",
    "#         flag = True\n",
    "\n",
    "print(output)\n",
    "array_list = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9220487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"entities\": [\n",
      "        {\n",
      "            \"id\": \"ent_1\",\n",
      "            \"name\": \"university\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"university_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_2\",\n",
      "            \"name\": \"student\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"student_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NNS\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_2\",\n",
      "            \"name\": \"student\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"student_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NNS\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NNS\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_2\",\n",
      "            \"name\": \"student\",\n",
      "            \"POS\": \"NNS\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"student_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                },\n",
      "                {\n",
      "                    \"attribute\": \"single\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_7\",\n",
      "            \"name\": \"professor\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"professor_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_9\",\n",
      "            \"name\": \"instruction\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"instruction_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_10\",\n",
      "            \"name\": \"quality\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"quality_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_7\",\n",
      "            \"name\": \"professor\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"professor_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"relations\": [\n",
      "        {\n",
      "            \"id\": \"r1\",\n",
      "            \"name\": \"enrolls\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_2\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r2\",\n",
      "            \"name\": \"assign\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_2\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r3\",\n",
      "            \"name\": \"assign\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_2\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r4\",\n",
      "            \"name\": \"teach\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r5\",\n",
      "            \"name\": \"maintain\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_9\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r6\",\n",
      "            \"name\": \"deliver\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#create JSON\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "entity_ids = {}\n",
    "# create the entity_ids dictionary\n",
    "\n",
    "for i, (word, pos, label) in enumerate(array_list):\n",
    "    if label == 'Entity' or label == 'Relation':\n",
    "        entity_ids.setdefault(word, f\"ent_{len(entity_ids) + 1}\")\n",
    "# create the entities and relations lists\n",
    "\n",
    "entities = []\n",
    "attributes = []\n",
    "relations = []\n",
    "entity_counter = 1\n",
    "attribute_counter = 1\n",
    "relation_counter = 1\n",
    "\n",
    "for i, (word, pos, label) in enumerate(array_list):\n",
    "    if label == 'Entity':\n",
    "        entities.append({\n",
    "            \"id\": entity_ids[word],\n",
    "            \"name\": word,\n",
    "            \"POS\": pos,\n",
    "            \"properties\": [\n",
    "                {\n",
    "                \"attribute\": f\"{word}_id\",\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "    elif label == 'Attribute':\n",
    "        entities[-1][\"properties\"].append({\n",
    "            \"attribute\": word\n",
    "        })\n",
    "         \n",
    "#     elif label == 'Attribute':\n",
    "#         if len(entities) > 0:\n",
    "#                 attribute_name = word.lower()\n",
    "#                 entities[-1]['attributes'].append(attribute_name)\n",
    "#                 attributes.append({\n",
    "#                     \"id\": f\"a{attribute_counter}\",\n",
    "#                     \"name\": attribute_name,\n",
    "#                     \"entity_id\": entities[-1]['id']\n",
    "#                 })\n",
    "#                 attribute_counter += 1\n",
    "        \n",
    "    elif label == 'Relation':\n",
    "        relation_name = word\n",
    "        if len(entities) >= 1:\n",
    "                relation_entity_ids = []\n",
    "                relation_entity_pos = []\n",
    "                for j in range(i-1, -1, -1):  # search backwards for the first entity\n",
    "                    if array_list[j][2]=='Entity':\n",
    "                        entity_name = array_list[j][0]\n",
    "                        if entity_name in entity_ids:\n",
    "                            relation_entity_ids.append(entity_ids[entity_name])\n",
    "                            relation_entity_pos.append(array_list[j][1])\n",
    "                            break\n",
    "                for j in range(i+1, len(array_list)):  # search forwards for the second entity\n",
    "                    if array_list[j][2]=='Entity':\n",
    "                        entity_name = array_list[j][0]\n",
    "                        if entity_name in entity_ids:\n",
    "                            relation_entity_ids.append(entity_ids[entity_name])\n",
    "                            relation_entity_pos.append(array_list[j][1])\n",
    "                            break\n",
    "                if len(relation_entity_ids) == 2:\n",
    "                    relations.append({\n",
    "                        \"id\": f\"r{relation_counter}\",\n",
    "                        \"name\": relation_name,\n",
    "                        \"entity_ids\": [\n",
    "                            {\n",
    "                                \"id\":relation_entity_ids[0],\n",
    "                                \"pos\":relation_entity_pos[0]\n",
    "                            },\n",
    "                            {\n",
    "                                \"id\":relation_entity_ids[1],\n",
    "                                \"pos\":relation_entity_pos[1]\n",
    "                            }\n",
    "                        ]\n",
    "                    })\n",
    "                    relation_counter += 1\n",
    "# create the JSON object\n",
    "er_diagram = {\n",
    "    \"entities\": entities,\n",
    "#     \"attribute\": attributes,\n",
    "    \"relations\": relations\n",
    "}\n",
    "\n",
    "# print the ER diagram as JSON\n",
    "# print(json.dumps(er_diagram, indent=4))\n",
    "json_=json.dumps(er_diagram, indent=4)\n",
    "print(json_)\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "324f5bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Entities\": [\n",
      "        {\n",
      "            \"id\": \"ent_1\",\n",
      "            \"name\": \"university\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"university_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_2\",\n",
      "            \"name\": \"student\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"student_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_4\",\n",
      "            \"name\": \"course\",\n",
      "            \"POS\": \"NNS\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"course_id\"\n",
      "                },\n",
      "                {\n",
      "                    \"attribute\": \"single\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_7\",\n",
      "            \"name\": \"professor\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"professor_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_9\",\n",
      "            \"name\": \"instruction\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"instruction_id\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"ent_10\",\n",
      "            \"name\": \"quality\",\n",
      "            \"POS\": \"NN\",\n",
      "            \"properties\": [\n",
      "                {\n",
      "                    \"attribute\": \"quality_id\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"Relationships\": [\n",
      "        {\n",
      "            \"id\": \"r1\",\n",
      "            \"name\": \"enrolls\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_2\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r3\",\n",
      "            \"name\": \"assign\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_2\",\n",
      "                    \"pos\": \"NNS\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r4\",\n",
      "            \"name\": \"teach\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r5\",\n",
      "            \"name\": \"maintain\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_9\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"r6\",\n",
      "            \"name\": \"deliver\",\n",
      "            \"entity_ids\": [\n",
      "                {\n",
      "                    \"id\": \"ent_7\",\n",
      "                    \"pos\": \"NN\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"ent_4\",\n",
      "                    \"pos\": \"NN\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# remove entity duplicates\n",
    "entities_dict = {}\n",
    "\n",
    "json_data = json.loads(json_)\n",
    "\n",
    "for entity in json_data['entities']:\n",
    "    entity_id = entity['id']\n",
    "    if entity_id in entities_dict:\n",
    "        # Entity already exists, update its properties\n",
    "        existing_entity = entities_dict[entity_id]\n",
    "        existing_properties = existing_entity['properties']\n",
    "        new_properties = entity['properties']\n",
    "        for new_prop in new_properties:\n",
    "            new_attr = new_prop['attribute']\n",
    "            if new_attr not in [prop['attribute'] for prop in existing_properties]:\n",
    "                existing_properties.append(new_prop)\n",
    "    else:\n",
    "        # Add entity to dictionary\n",
    "        entities_dict[entity_id] = entity\n",
    "\n",
    "# remove duplicates in relations\n",
    "\n",
    "# Iterate over each relation and check for duplicates\n",
    "i = 0\n",
    "while i < len(relations):\n",
    "    relation = relations[i]\n",
    "    duplicate_found = False\n",
    "    \n",
    "    # Check for duplicates\n",
    "    for other_relation in relations:\n",
    "        if other_relation != relation and other_relation['name'] == relation['name']:\n",
    "            if set([entity['id'] for entity in other_relation['entity_ids']]) == set([entity['id'] for entity in relation['entity_ids']]):\n",
    "                duplicate_found = True\n",
    "                break\n",
    "    \n",
    "    # Remove the duplicate if found\n",
    "    if duplicate_found:\n",
    "        relations.pop(i)\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# Convert dictionary back to list of entities\n",
    "entities_list = list(entities_dict.values())\n",
    "er_diagram = {\n",
    "    \"Entities\": entities_list,\n",
    "    \"Relationships\": relations\n",
    "}\n",
    "\n",
    "# Convert list of entities back to JSON string\n",
    "output_json = json.dumps(er_diagram, indent=4)\n",
    "\n",
    "print(output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5048c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing code to remove non related entities\n",
    "# data = json.loads(output_json)\n",
    "\n",
    "# entity_ids = [entity[\"id\"] for entity in data[\"Entities\"]]\n",
    "# relationship_entity_ids = [entity[\"id\"] for relationship in data[\"Relationships\"] for entity in relationship[\"entity_ids\"]]\n",
    "\n",
    "# for entity in data[\"Entities\"]:\n",
    "#     if entity[\"id\"] not in relationship_entity_ids:\n",
    "#         data[\"Entities\"].remove(entity)\n",
    "\n",
    "# output_json = json.dumps(data, indent=4)\n",
    "# print(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3449e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to draw ER without cardinality\n",
    "\n",
    "er_diagram = json.loads(output_json)\n",
    "\n",
    "# Create a Graphviz graph\n",
    "graph = Digraph()\n",
    "# graph = Digraph(graph_attr={'rankdir': 'LR'})\n",
    "\n",
    "# sample set to add all the edges. This helps to avoid repeted edges\n",
    "added_edges = set()\n",
    "\n",
    "# Add the entities and their properties as nodes to the graph\n",
    "for entity in er_diagram['Entities']:\n",
    "    graph.node(entity['id'], entity['name'], shape='rectangle')\n",
    "\n",
    "    for property in entity['properties']:\n",
    "        node_id = f\"{entity['id']}_{property['attribute']}\"\n",
    "        graph.node(node_id, property['attribute'])\n",
    "        edge = (entity['id'], node_id)\n",
    "        if edge not in added_edges:\n",
    "            graph.edge(*edge, dir=\"none\")\n",
    "            added_edges.add(edge)\n",
    "\n",
    "# Add the relations and their entities as nodes to the graph\n",
    "for relation in er_diagram['Relationships']:\n",
    "    graph.node(relation['id'], relation['name'], shape='diamond')\n",
    "    for entity in relation['entity_ids']:\n",
    "        edge = (entity['id'], relation['id'])\n",
    "        if edge not in added_edges:\n",
    "            graph.edge(*edge, dir=\"none\")\n",
    "            added_edges.add(edge)\n",
    "\n",
    "# Render the Graphviz graph and save it as a PNG image\n",
    "graph.render('er_diagram', format='png')\n",
    "\n",
    "# Open the image using PIL\n",
    "im = Image.open('er_diagram.png')\n",
    "\n",
    "# Display the image in the console\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8def9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
